{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e952d170-d198-4b0c-984b-669b85770795",
   "metadata": {},
   "source": [
    "# Guide to Unique Decoding of Reed-Solomon Codes\n",
    "\n",
    "This notebook provides the explanation and implementation of the **Welch-Berlekamp algorithm** for the unique decoding of Reed-Solomon codes. We will start by defining the unique decoding problem, develop the intuition behind the algorithm using a geometric perspective, and finally build and demonstrate a working Python implementation.\n",
    "\n",
    "## The Unique Decoding Problem\n",
    "\n",
    "A Reed-Solomon code is created by taking a message, treating it as the coefficients of a **message polynomial** $P(X)$ of degree less than $k$, and then evaluating that polynomial at $n$ distinct points $(\\alpha_1, \\dots, \\alpha_n)$ to create a codeword.\n",
    "\n",
    "When this codeword is transmitted, a noisy channel may introduce errors, resulting in a **received word** $y = (y_1, \\dots, y_n)$. The number of errors, $e$, is the number of positions where the received word differs from the original codeword.\n",
    "\n",
    "The goal of **unique decoding** is to recover the *one and only* original polynomial $P(X)$ from the noisy received word $y$. This is only guaranteed to be possible if the number of errors is strictly less than half the minimum distance of the code. For a Reed-Solomon code, this condition is:\n",
    "\n",
    "$$ e < \\frac{n-k+1}{2} $$\n",
    "\n",
    "This notebook will build the Welch-Berlekamp algorithm, an efficient method for solving this exact problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6436473-b1eb-4af8-99c9-d9b00b9ddeaa",
   "metadata": {},
   "source": [
    "## A Geometric View of the Problem \n",
    "\n",
    "To better visualize the problem, we can perform a \"syntactic shift\" and think of the received word $y$ not as a vector, but as a collection of $n$ points in a 2D plane: $\\{(\\alpha_1, y_1), (\\alpha_2, y_2), \\dots, (\\alpha_n, y_n)\\}$.\n",
    "\n",
    "<img src=\"./imgs/image_unique_decoding_1.png\" width=\"600\"/>\n",
    "\n",
    "The image above shows an example of a received word with n=14 points and k=2. The original message was a line (a polynomial of degree k-1=1).\n",
    "\n",
    "The original, uncorrupted codeword would consist of points that all lie perfectly on the curve defined by the message polynomial $P(X)$. The effect of noise is to knock some of these points off the curve. The decoder's job, in this geometric view, is to find the unique curve of degree less than $k$ that passes through the maximum number of these received points.\n",
    "\n",
    "<img src=\"./imgs/image_unique_decoding_2.png\"  width=\"600\"/>\n",
    "\n",
    "The above image illustrates this. The correct polynomial, $P(X)=X$, passes through the subset of \"correct\" points, while the \"error\" points lie scattered off the line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c73a071-c311-47cc-963c-1fe87eab6a29",
   "metadata": {},
   "source": [
    "## The Core Idea: Reverse Engineering a Solution \n",
    "\n",
    "The Welch-Berlekamp algorithm is designed using a \"reverse engineering\" approach. We start by assuming we magically know the solution—both the original polynomial $P(X)$ and the locations of the errors—and derive a mathematical property. Then, we use that property to build an algorithm that finds $P(X)$ without knowing the error locations beforehand.\n",
    "\n",
    "### The Error-Locator Polynomial, E(X)\n",
    "\n",
    "Let's define a special tool called the **Error-Locator Polynomial**, $E(X)$. This is a polynomial whose roots are the x-coordinates ($\\alpha_i$) where an error occurred. In other words:\n",
    "\n",
    "$$ E(\\alpha_i) = 0 \\quad \\text{if} \\quad y_i \\neq P(\\alpha_i) $$\n",
    "\n",
    "If there are $e$ errors, we can construct such a polynomial of degree $e$.\n",
    "\n",
    "### The Key Equation\n",
    "\n",
    "With this definition, we can establish a key equation that holds true for **every single point**, whether it's an error or not:\n",
    "\n",
    "$$ y_i E(\\alpha_i) = P(\\alpha_i) E(\\alpha_i) \\quad \\text{for all } i=1, \\dots, n $$\n",
    "\n",
    "\n",
    "This powerful identity is easy to prove by considering two cases:\n",
    "1.  **If an error occurred at $\\alpha_i$**: By definition, $E(\\alpha_i) = 0$. The equation becomes $y_i \\cdot 0 = P(\\alpha_i) \\cdot 0$, which simplifies to $0=0$. The identity holds.\n",
    "2.  **If no error occurred at $\\alpha_i$**: In this case, we know $y_i = P(\\alpha_i)$. If we multiply both sides of this by $E(\\alpha_i)$, the equality is preserved. The identity also holds.\n",
    "\n",
    "This equation is the foundation of the algorithm. The only problem is that it involves the product of two unknowns, $P(X)$ and $E(X)$, making it a difficult quadratic problem to solve directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dff371-71a9-4941-9491-fec65e21e0db",
   "metadata": {},
   "source": [
    "## The Core Idea: Reverse Engineering a Solution \n",
    "\n",
    "The Welch-Berlekamp algorithm is designed using a clever \"reverse engineering\" approach. We start by assuming we magically know the solution—both the original polynomial $P(X)$ and the locations of the errors—and derive a mathematical property. Then, we use that property to build an algorithm that finds $P(X)$ without knowing the error locations beforehand.\n",
    "\n",
    "### The Error-Locator Polynomial, E(X)\n",
    "\n",
    "Let's define a special tool called the **Error-Locator Polynomial**, $E(X)$. This is a polynomial whose roots are the x-coordinates ($\\alpha_i$) where an error occurred. In other words:\n",
    "\n",
    "$$ E(\\alpha_i) = 0 \\quad \\text{if} \\quad y_i \\neq P(\\alpha_i) $$\n",
    "\n",
    "If there are $e$ errors, we can construct such a polynomial of degree $e$.\n",
    "\n",
    "### The Key Equation\n",
    "\n",
    "With this definition, we can establish a key equation that holds true for **every single point**, whether it's an error or not:\n",
    "\n",
    "$$ y_i E(\\alpha_i) = P(\\alpha_i) E(\\alpha_i) \\quad \\text{for all } i=1, \\dots, n $$\n",
    "\n",
    "\n",
    "This powerful identity is easy to prove by considering two cases:\n",
    "1.  **If an error occurred at $\\alpha_i$**: By definition, $E(\\alpha_i) = 0$. The equation becomes $y_i \\cdot 0 = P(\\alpha_i) \\cdot 0$, which simplifies to $0=0$. The identity holds.\n",
    "2.  **If no error occurred at $\\alpha_i$**: In this case, we know $y_i = P(\\alpha_i)$. If we multiply both sides of this by $E(\\alpha_i)$, the equality is preserved. The identity also holds.\n",
    "\n",
    "This equation is the foundation of the algorithm. The only problem is that it involves the product of two unknowns, $P(X)$ and $E(X)$, making it a difficult quadratic problem to solve directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568da536-6109-46c2-80da-dcf470a27d42",
   "metadata": {},
   "source": [
    "## The Welch-Berlekamp Algorithm\n",
    "\n",
    "The genius of Welch-Berlekamp is a **linearization trick** that transforms the difficult quadratic problem into a simple system of linear equations that we know how to solve efficiently.\n",
    "\n",
    "### The Linearization Trick\n",
    "\n",
    "We define a new \"numerator\" polynomial, $N(X)$, as the product of our two unknowns:\n",
    "\n",
    "$$ N(X) \\triangleq P(X) \\cdot E(X) $$\n",
    "\n",
    "By substituting this into our key equation, we get a new equation where the unknowns—the coefficients of $N(X)$ and $E(X)$—appear linearly:\n",
    "\n",
    "$$ N(\\alpha_i) = y_i E(\\alpha_i) \\quad \\text{for all } i=1, \\dots, n $$\n",
    "\n",
    "\n",
    "Now, our goal is to find the two polynomials $N(X)$ and $E(X)$ that satisfy this linear system. If we can find them, we can recover the original message polynomial by simply performing a polynomial division:\n",
    "\n",
    "$$ P(X) = \\frac{N(X)}{E(X)} $$\n",
    "\n",
    "This leads to the formal three-step algorithm.\n",
    "\n",
    "### The Algorithm Steps\n",
    "\n",
    "1.  **Interpolation (Solve Linear System):** Find non-zero polynomials $N(X)$ (of degree at most $k+e-1$) and $E(X)$ (of degree at most $e$) that satisfy the system of $n$ linear equations $N(\\alpha_i) = y_i E(\\alpha_i)$ for all received points $(\\alpha_i, y_i)$.\n",
    "\n",
    "2.  **Division (Find P(X)):** If a solution is found and $E(X)$ divides $N(X)$, compute the candidate message polynomial by division: $P(X) = N(X) / E(X)$. If not, the decoding fails.\n",
    "\n",
    "3.  **Verification:** Check if the recovered $P(X)$ is a valid solution by ensuring it is \"close\" to the received word $y$ (i.e., the number of disagreements is at most $e$). If it is, return $P(X)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af216839-051e-4f6d-a690-983f494d851f",
   "metadata": {},
   "source": [
    "## Code Implementation & Demonstration \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1a3543e-855f-4316-9e57-28247cb7aae1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original message: 'abc' (k=3)\n",
      "Message ASCII coefficients: [97, 98, 99]\n",
      "Message polynomial P(X): 99*x^2 + 98*x + 97\n",
      "\n",
      "Encoded codeword (n=7): [(0, 97), (1, 37), (2, 175), (3, 254), (4, 17), (5, 235), (6, 137)]\n",
      "Noisy word with 2 errors: [(0, 97), (1, 37), (2, 99), (3, 254), (4, 17), (5, 42), (6, 137)]\n",
      "\n",
      "--- Starting Welch-Berlekamp Decoder ---\n",
      "This [n=7, k=3] code can correct up to e=2 errors.\n",
      "\n",
      "Solving a 7x7 linear system for the coefficients...\n",
      "Found polynomials:\n",
      "  N(X) = 99*x^4 + 176*x^3 + 144*x^2 + 44*x + 199\n",
      "  E(X) = x^2 + 250*x + 10\n",
      "\n",
      "Found candidate message polynomial P(X) = 99*x^2 + 98*x + 97\n",
      "Verification: Found 2 disagreements with the received word.\n",
      "\n",
      "Converting polynomial coefficients [97, 98, 99] back to message...\n",
      "\n",
      "SUCCESS! Decoded message: 'abc'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'abc'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from sage.all import *\n",
    "\n",
    "# Define the finite field we will work in\n",
    "F = GF(257)\n",
    "\n",
    "# Helper function to convert a message to a polynomial\n",
    "def msg_to_poly(msg_coeffs, R):\n",
    "    return R(list(msg_coeffs))\n",
    "\n",
    "# Helper function to convert a polynomial back to a message\n",
    "def poly_to_msg(poly, k):\n",
    "    coeffs = poly.coefficients(sparse=False)\n",
    "    # Pad with zeros if necessary\n",
    "    while len(coeffs) < k:\n",
    "        coeffs.append(0)\n",
    "    \n",
    "    # NEW: Descriptive print statement\n",
    "    print(f\"\\nConverting polynomial coefficients {coeffs} back to message...\")\n",
    "    return \"\".join([chr(int(c)) for c in coeffs])\n",
    "\n",
    "# Main Welch-Berlekamp Decoder Function\n",
    "def welch_berlekamp_decode(points, n, k):\n",
    "    print(\"\\n--- Starting Welch-Berlekamp Decoder ---\")\n",
    "    \n",
    "    e = (n - k + 1) // 2\n",
    "    print(f\"This [n={n}, k={k}] code can correct up to e={e} errors.\")\n",
    "\n",
    "    R_x = PolynomialRing(F, 'x')\n",
    "    \n",
    "    # Step 1: Solve the Linear System for N(X) and E(X)\n",
    "    num_N_coeffs = k + e \n",
    "    num_E_coeffs = e \n",
    "    num_vars = num_N_coeffs + num_E_coeffs\n",
    "\n",
    "    M = MatrixSpace(F, n, num_vars)\n",
    "    matrix = M()\n",
    "    b = vector(F, n)\n",
    "\n",
    "    for i in range(n):\n",
    "        alpha_i, y_i = points[i]\n",
    "        \n",
    "        # Build matrix row for N(X) and E(X) coefficients\n",
    "        for j in range(num_N_coeffs):\n",
    "            matrix[i, j] = alpha_i**j\n",
    "        for j in range(num_E_coeffs):\n",
    "            matrix[i, num_N_coeffs + j] = -y_i * (alpha_i**j)\n",
    "        \n",
    "        # Build the constant vector `b` from the E_e=1 term\n",
    "        b[i] = y_i * (alpha_i**e)\n",
    "\n",
    "    print(f\"\\nSolving a {n}x{num_vars} linear system for the coefficients...\")\n",
    "    \n",
    "    try:\n",
    "        solution = matrix.solve_right(b)\n",
    "    except ValueError:\n",
    "        print(\"Decoding Failed: The linear system has no unique solution.\")\n",
    "        return None\n",
    "\n",
    "    N_coeffs = list(solution[:num_N_coeffs])\n",
    "    E_coeffs = list(solution[num_N_coeffs:]) + [1] # Add the implicit e_e=1 coefficient\n",
    "    \n",
    "    N = R_x(N_coeffs)\n",
    "    E = R_x(E_coeffs)\n",
    "    \n",
    "    print(f\"Found polynomials:\\n  N(X) = {N}\\n  E(X) = {E}\")\n",
    "    \n",
    "    # Step 2: Division to find P(X)\n",
    "    if E == 0 or N % E != 0:\n",
    "        print(\"\\nDecoding Failed: E(X) does not divide N(X).\")\n",
    "        return None\n",
    "        \n",
    "    P_candidate = N // E\n",
    "    print(f\"\\nFound candidate message polynomial P(X) = {P_candidate}\")\n",
    "    \n",
    "    # Step 3: Verification\n",
    "    encoded_candidate = [(alpha, P_candidate(alpha)) for alpha, y in points]\n",
    "    disagreements = 0\n",
    "    for i in range(n):\n",
    "        if points[i][1] != encoded_candidate[i][1]:\n",
    "            disagreements += 1\n",
    "            \n",
    "    print(f\"Verification: Found {disagreements} disagreements with the received word.\")\n",
    "    \n",
    "    if disagreements <= e:\n",
    "        decoded_msg = poly_to_msg(P_candidate, k)\n",
    "        print(f\"\\nSUCCESS! Decoded message: '{decoded_msg}'\")\n",
    "        return decoded_msg\n",
    "    else:\n",
    "        print(\"\\nDecoding Failed: Candidate polynomial is too far from the received word.\")\n",
    "        return None\n",
    "\n",
    "# --- Demonstration ---\n",
    "\n",
    "# Parameters\n",
    "msg = \"abc\"\n",
    "k = len(msg)\n",
    "n = 7\n",
    "\n",
    "# Message -> Polynomial\n",
    "R_x = PolynomialRing(F, 'x')\n",
    "msg_coeffs = [ord(c) for c in msg]\n",
    "\n",
    "# NEW: Descriptive print statement\n",
    "print(f\"Original message: '{msg}' (k={k})\")\n",
    "print(f\"Message ASCII coefficients: {msg_coeffs}\")\n",
    "P = msg_to_poly(msg_coeffs, R_x)\n",
    "print(f\"Message polynomial P(X): {P}\")\n",
    "\n",
    "# Encoding\n",
    "alphas = [F(i) for i in range(n)]\n",
    "codeword = [(alpha, P(alpha)) for alpha in alphas]\n",
    "print(f\"\\nEncoded codeword (n={n}): {codeword}\")\n",
    "\n",
    "# Introduce Errors\n",
    "e_limit = (n - k + 1) // 2\n",
    "num_errors = 2 # This is <= e_limit, so it's correctable\n",
    "noisy_word = list(codeword)\n",
    "noisy_word[2] = (alphas[2], F(99)) # Corrupt point 2\n",
    "noisy_word[5] = (alphas[5], F(42)) # Corrupt point 5\n",
    "print(f\"Noisy word with {num_errors} errors: {noisy_word}\")\n",
    "\n",
    "# Decode\n",
    "welch_berlekamp_decode(noisy_word, n, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59062de7-1394-4a0d-a10e-eed911bc2792",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
